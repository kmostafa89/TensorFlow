{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income = pd.read_csv(\"census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "education_num      int64\n",
       "capital_gain       int64\n",
       "capital_loss       int64\n",
       "hours_per_week     int64\n",
       "workclass         object\n",
       "education         object\n",
       "marital_status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "gender            object\n",
       "native_country    object\n",
       "income_bracket    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.dtypes.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workclass', 'education', 'marital_status', 'occupation',\n",
       "       'relationship', 'race', 'gender', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col = income.columns[income.dtypes!=np.int64]\n",
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education_num', 'capital_gain', 'capital_loss',\n",
       "       'hours_per_week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col = income.columns[income.dtypes ==np.int64]\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.income_bracket.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "income.income_bracket = income.income_bracket.map({' <=50K':0 ,' >50K':1 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = income.drop(\"income_bracket\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = income.income_bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y , test_size = 0.3 , random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_col = cat_col.drop(\"income_bracket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['workclass', 'education', 'marital_status', 'occupation',\n",
       "       'relationship', 'race', 'gender', 'native_country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_cat_col = []\n",
    "for i in cat_col:\n",
    "    new_cat_col.append(i+\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "test_cat_col= {}\n",
    "for name , col in zip( new_cat_col , cat_col):\n",
    "    test_cat_col[name] = tf.feature_column.categorical_column_with_hash_bucket(col,hash_bucket_size=50)\n",
    "    test_cat_col[name] = tf.feature_column.embedding_column(test_cat_col[name],dimension = 50)\n",
    "    feat_cols.append(test_cat_col[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C550>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='education', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C0F0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='marital_status', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C470>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C828>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='relationship', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C908>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='race', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C710>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='gender', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C198>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524CB00>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_num_col = []\n",
    "for i in num_col:\n",
    "    new_num_col.append(i+\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_num_col = {}\n",
    "for name , col in zip(new_num_col, num_col):\n",
    "    test_num_col[name] = tf.feature_column.numeric_column(col)\n",
    "    feat_cols.append(test_num_col[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C550>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='education', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C0F0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='marital_status', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C470>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C828>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='relationship', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C908>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='race', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C710>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='gender', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C198>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524CB00>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globals().update(test_num_col)\n",
    "globals().update(test_cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass_\n",
      "education_\n",
      "marital_status_\n",
      "occupation_\n",
      "relationship_\n",
      "race_\n",
      "gender_\n",
      "native_country_\n"
     ]
    }
   ],
   "source": [
    "for i in test_cat_col.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093A20>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workclass_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass_ = tf.feature_column.embedding_column(workclass_, dimension=50)\n",
    "education_ = tf.feature_column.embedding_column(education_,dimension=50)\n",
    "marital_status_ = tf.feature_column.embedding_column(marital_status_,dimension=50)\n",
    "occupation_ = tf.feature_column.embedding_column(occupation_,dimension=50)\n",
    "relationship_ = tf.feature_column.embedding_column(relationship_,dimension=50)\n",
    "race_ = tf.feature_column.embedding_column(race_,dimension=50)\n",
    "gender_ = tf.feature_column.embedding_column(gender_,dimension=50)\n",
    "native_country_ = tf.feature_column.embedding_column(native_country_,dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['workclass_', 'education_', 'marital_status_', 'occupation_', 'relationship_', 'race_', 'gender_', 'native_country_'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat_col.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_cols = [age_, capital_loss_,capital_gain_,education_num_,hours_per_week_,\n",
    "            workclass_, education_, marital_status_,occupation_,relationship_,race_,gender_,native_country_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C550>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='education', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C0F0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='marital_status', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C470>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C828>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='relationship', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C908>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='race', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C710>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='gender', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524C198>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F524CB00>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)\n",
      "_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "_NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "_NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "_NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "_NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
     ]
    }
   ],
   "source": [
    "for i in feat_cols:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(X_train , y_train , batch_size = 10, num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "units = []\n",
    "for i in range(3):\n",
    "    units.append(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Mostafa\\AppData\\Local\\Temp\\tmp89t2ox1t\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Mostafa\\\\AppData\\\\Local\\\\Temp\\\\tmp89t2ox1t', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNClassifier(hidden_units=units,feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='workclass', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093A20>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='education', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093A58>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='marital_status', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093AC8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093B00>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='relationship', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093B38>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='race', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093B70>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='gender', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093BA8>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True),\n",
       " _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='native_country', hash_bucket_size=50, dtype=tf.string), dimension=50, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000001A4F3093BE0>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Marcial\\AppData\\Local\\Temp\\tmpyyyqnxgv\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\Marcial\\\\AppData\\\\Local\\\\Temp\\\\tmpyyyqnxgv', '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_save_summary_steps': 100, '_tf_random_seed': 1}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Mostafa\\AppData\\Local\\Temp\\tmp89t2ox1t\\model.ckpt.\n",
      "INFO:tensorflow:loss = 7.69124, step = 1\n",
      "INFO:tensorflow:global_step/sec: 274.657\n",
      "INFO:tensorflow:loss = 6.19514, step = 101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.343\n",
      "INFO:tensorflow:loss = 4.21423, step = 201 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.805\n",
      "INFO:tensorflow:loss = 5.14295, step = 301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.912\n",
      "INFO:tensorflow:loss = 3.15695, step = 401 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.245\n",
      "INFO:tensorflow:loss = 3.9846, step = 501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.192\n",
      "INFO:tensorflow:loss = 2.32466, step = 601 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.714\n",
      "INFO:tensorflow:loss = 3.8014, step = 701 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.722\n",
      "INFO:tensorflow:loss = 3.12984, step = 801 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.804\n",
      "INFO:tensorflow:loss = 2.97455, step = 901 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.157\n",
      "INFO:tensorflow:loss = 3.98261, step = 1001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.866\n",
      "INFO:tensorflow:loss = 2.45127, step = 1101 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.273\n",
      "INFO:tensorflow:loss = 3.08328, step = 1201 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.039\n",
      "INFO:tensorflow:loss = 3.99751, step = 1301 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.812\n",
      "INFO:tensorflow:loss = 4.18384, step = 1401 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.08\n",
      "INFO:tensorflow:loss = 6.58443, step = 1501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.052\n",
      "INFO:tensorflow:loss = 3.8788, step = 1601 (0.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.941\n",
      "INFO:tensorflow:loss = 2.86201, step = 1701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.811\n",
      "INFO:tensorflow:loss = 2.10194, step = 1801 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.868\n",
      "INFO:tensorflow:loss = 2.83361, step = 1901 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 325.929\n",
      "INFO:tensorflow:loss = 1.5507, step = 2001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.535\n",
      "INFO:tensorflow:loss = 2.21952, step = 2101 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.667\n",
      "INFO:tensorflow:loss = 2.05879, step = 2201 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.556\n",
      "INFO:tensorflow:loss = 5.1852, step = 2301 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.943\n",
      "INFO:tensorflow:loss = 3.63809, step = 2401 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.356\n",
      "INFO:tensorflow:loss = 0.999395, step = 2501 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.073\n",
      "INFO:tensorflow:loss = 1.62929, step = 2601 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.536\n",
      "INFO:tensorflow:loss = 4.22813, step = 2701 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.806\n",
      "INFO:tensorflow:loss = 2.28266, step = 2801 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.678\n",
      "INFO:tensorflow:loss = 2.67278, step = 2901 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.944\n",
      "INFO:tensorflow:loss = 4.51028, step = 3001 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.998\n",
      "INFO:tensorflow:loss = 1.36193, step = 3101 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.67\n",
      "INFO:tensorflow:loss = 2.40361, step = 3201 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.081\n",
      "INFO:tensorflow:loss = 6.64502, step = 3301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.665\n",
      "INFO:tensorflow:loss = 2.024, step = 3401 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.245\n",
      "INFO:tensorflow:loss = 6.54782, step = 3501 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.558\n",
      "INFO:tensorflow:loss = 3.793, step = 3601 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.946\n",
      "INFO:tensorflow:loss = 2.3794, step = 3701 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.325\n",
      "INFO:tensorflow:loss = 2.82606, step = 3801 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.471\n",
      "INFO:tensorflow:loss = 3.57784, step = 3901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 351.174\n",
      "INFO:tensorflow:loss = 2.86487, step = 4001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.561\n",
      "INFO:tensorflow:loss = 2.26863, step = 4101 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.756\n",
      "INFO:tensorflow:loss = 2.48918, step = 4201 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.389\n",
      "INFO:tensorflow:loss = 3.81057, step = 4301 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.669\n",
      "INFO:tensorflow:loss = 6.48219, step = 4401 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.757\n",
      "INFO:tensorflow:loss = 2.72268, step = 4501 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.073\n",
      "INFO:tensorflow:loss = 2.90719, step = 4601 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.67\n",
      "INFO:tensorflow:loss = 2.07818, step = 4701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.72\n",
      "INFO:tensorflow:loss = 5.21132, step = 4801 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.805\n",
      "INFO:tensorflow:loss = 1.47691, step = 4901 (0.299 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\Mostafa\\AppData\\Local\\Temp\\tmp89t2ox1t\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.6715.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1a4f4d376d8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_func = tf.estimator.inputs.pandas_input_fn(X_test  , batch_size=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    " result = dnn_model.predict(eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Mostafa\\AppData\\Local\\Temp\\tmp89t2ox1t\\model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "result = list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.24901748], dtype=float32),\n",
       " 'logits': array([-1.10385931], dtype=float32),\n",
       " 'probabilities': array([ 0.75098246,  0.24901746], dtype=float32)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logistic': array([ 0.21327116], dtype=float32),\n",
       " 'logits': array([-1.30531931], dtype=float32),\n",
       " 'probabilities': array([ 0.78672886,  0.21327116], dtype=float32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = []\n",
    "for i in result:\n",
    "    class_id.append(int(i[\"class_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_id[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_test, class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.95      0.90      7436\n",
      "          1       0.74      0.47      0.57      2333\n",
      "\n",
      "avg / total       0.82      0.83      0.82      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90      7436\n",
      "          1       0.70      0.59      0.64      2333\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
